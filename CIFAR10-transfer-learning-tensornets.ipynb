{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "\"\"\" \n",
    "    check if the data (zip) file is already downloaded\n",
    "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
    "\"\"\"\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 7000\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/test/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensornets as nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 model\n",
    "- input image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10), name='output_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.VGG16(x, is_training=True, classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-39ea3c2790d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mload_preprocess_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:>2}, CIFAR-10 Batch {}:  '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                sess.run(train, {x: batch_features, y: batch_labels})\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    nets.pretrained(model)\n",
    "    # for (x, y) in your NumPy data (the NHWC and one-hot format):\n",
    "        sess.run(train, {inputs: x, outputs: y})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
